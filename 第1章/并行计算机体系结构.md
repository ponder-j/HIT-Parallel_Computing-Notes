## 并行系统分类
### Flynn 分类法
SISD：Single Instruction Single data 串行计算机
SIMD：Single Instruction Multiple Data 适用性有限，GPU 思想
MISD：Multiple Instruction Single Data 没卵用，现实中也没有
MIMD：Multiple Instruction Multiple Data 常见的并行计算机都可归入此类

#### SISD
``` mermaid
graph LR
    CU[CU<br/>控制单元]
    PU[PU<br/>处理单元]
    MM[MM<br/>存储器]
    
    CU --> PU
    PU -->|DS<br/>数据流| MM
    MM -->|IS<br/>指令流| CU
    
    style CU fill:#e1b3e5
    style PU fill:#b3e5e1
    style MM fill:#e5e5b3
```

#### SIMD
```mermaid
graph LR
    CU[CU<br/>控制单元]
    
    PU1[PU]
    PU2[PU]
    PU3[PU]
    
    subgraph MM_Group[存储器组]
        MM1[MM]
        MM2[MM]
        MM3[...]
        MM4[MM]
    end
    
    CU --> PU1
    CU --> PU2
    CU --> PU3
    
    PU1 -->|DS1| MM1
    PU2 -->|DS2| MM2
    PU2 --> MM3
    PU3 -->|DSn| MM4
    
    MM_Group -->|IS<br/>指令流| CU
    
    style CU fill:#e1b3e5
    style PU1 fill:#b3e5e1
    style PU2 fill:#b3e5e1
    style PU3 fill:#b3e5e1
    style MM1 fill:#e5e5b3
    style MM2 fill:#e5e5b3
    style MM3 fill:#e5e5b3
    style MM4 fill:#e5e5b3
```

#### MISD
```mermaid
graph LR
    %% --- 存储器组（竖直排列） ---
    subgraph MM_Group[存储器组]
        direction TB
        MM1[MM]
        MM2[...]
        MM3[MM]
    end
    
    %% --- 控制单元组 ---
    CU1[CU1]
    CU2[CU2]
    CU3[...]
    CU4[CUn]
    
    %% --- 处理单元组 ---
    PU1[PU1]
    PU2[PU2]
    PU3[...]
    PU4[PUn]
    
    %% --- 连接关系 ---
    MM_Group -->|IS1| CU1
    MM_Group -->|IS2| CU2
    MM_Group --> CU3
    MM_Group -->|ISn| CU4
    
    CU1 --> PU1
    CU2 --> PU2
    CU3 --> PU3
    CU4 --> PU4
    
    %% --- 数据流改动 ---
    MM_Group -->|DS| PU1
    PU1 --> PU2
    PU2 --> PU3
    PU3 --> PU4
    PU4 --> MM_Group
    
    %% --- 样式 ---
    style MM1 fill:#e5e5b3
    style MM2 fill:#e5e5b3
    style MM3 fill:#e5e5b3
    style CU1 fill:#e1b3e5
    style CU2 fill:#e1b3e5
    style CU3 fill:#e1b3e5
    style CU4 fill:#e1b3e5
    style PU1 fill:#b3e5e1
    style PU2 fill:#b3e5e1
    style PU3 fill:#b3e5e1
    style PU4 fill:#b3e5e1

```

```mermaid
graph TD
    A[计算机体系结构] --> B[SISD 冯诺依曼]
    A --> C[SIMD]
    A --> D[MISD]
    A --> E[MIMD]
    
    C --> F[向量计算机]
    C --> G[阵列计算机]
    
    E --> H[多处理机]
    E --> I[多计算机]
    
    H --> J[UMA]
    H --> K[COMA]
    H --> L[NUMA]
    
    I --> M[MPP]
    I --> N[COW]
    
    J --> O[总线]
    J --> P[交换结构]
    
    L --> Q[CC-NUMA]
    L --> R[NC-NUMA]
    
    subgraph 共享内存
	O
	P
	Q
	R
	end
    
    M --> S[网格]
    M --> T[超立方体]
    
    subgraph 消息传递
    S
    T
	end
    
    style A fill:#b0e0e6,stroke:#333,stroke-width:3px
    style B fill:#d3d3d3,stroke:#333,stroke-width:2px
    style C fill:#d3d3d3,stroke:#333,stroke-width:2px
    style D fill:#d3d3d3,stroke:#333,stroke-width:2px
    style E fill:#d3d3d3,stroke:#333,stroke-width:2px
    style F fill:#e0e0e0,stroke:#333,stroke-width:2px
    style G fill:#e0e0e0,stroke:#333,stroke-width:2px
    style H fill:#e0e0e0,stroke:#333,stroke-width:2px
    style I fill:#e0e0e0,stroke:#333,stroke-width:2px
    style J fill:#f0f0f0,stroke:#333,stroke-width:2px
    style K fill:#f0f0f0,stroke:#333,stroke-width:2px
    style L fill:#f0f0f0,stroke:#333,stroke-width:2px
    style M fill:#f0f0f0,stroke:#333,stroke-width:2px
    style N fill:#f0f0f0,stroke:#333,stroke-width:2px
    style O fill:#f5f5f5,stroke:#333,stroke-width:1px
    style P fill:#f5f5f5,stroke:#333,stroke-width:1px
    style Q fill:#f5f5f5,stroke:#333,stroke-width:1px
    style R fill:#f5f5f5,stroke:#333,stroke-width:1px
    style S fill:#f5f5f5,stroke:#333,stroke-width:1px
    style T fill:#f5f5f5,stroke:#333,stroke-width:1px
```
## 共享内存系统
### UMA
### NUMA
- Non-Uniform Memory Access 非均匀存储器访问
	- 共享存储器分布在所有的处理器中
	- 处理器访问存储器的**时间不均匀**
	- 每台处理器可带**私有**高速缓存
	- **外设**可以一定形式**共享**
### CC-NUMA
- Coherent-Cache Nonuniform Memory Access 告诉缓存一致性非均匀存储访问
	- 大多数使用基于目录的高速缓存一致性协议
	- 保留 SMP 易于编程的优点，改善常规 SMP 的可扩放性
	- 分布共享存储的 DSM 多处理机系统
	- 程序员无需明确地在节点上分配数据
- UMA 和 NUMA 的一个折中方案
### COMA
- Cache-Only Memory Access 全高速缓存存取
	- 没有存储层次结构，全部高速缓存组成全局地址空间
	- 利用分布的高速缓存目录进行远程高速缓存的访问
	- COMA 中的高速缓存容量一般**大于2级**高速缓存容量
	- 数据开始时可以**任意分配**
- 激进的方案，把 Cache 的概念发挥到极致

## 分布式内存系统
- 通用多计算机体系结构
	- 每个节点都由一个或者多个 CPU、RAM、磁盘以及其他的输入/输出设备和通信处理器组成
	- 通信处理器通过**互连网络**相互连接起来，可以使用多种不同的**拓扑结构**，交换策略和寻径算法
### MPP
- Massively Parallel Processor  大规模并行处理机
	- 由成百上千台处理机组成的大规模并行计算机系统
	- 过去主要用于科学计算、工程模拟等以计算为主的场合，目前也广泛应用于商业和网络应用中
	- 开发困难，价格高，市场有限，是国家综合实力的象征
- 系统特点
	- 一般使用标准的商用 CPU 作为它们的处理器
	- 使用了高性能的私用的互连网络，可以在低延时和高带宽的条件下传递消息
	- 具有强大的输入输出能力
	- 能够进行卓越的容错处理
- LM: Local Memory 本地存储
- NIC: Network Interface Card(?) 网络接口电路
- MB: Memory Bus 存储器总线
### Cluster
- Cluster 集群（COW机群）
	- 由大量的PC机或者工作站通过商用网络连接在一起构成
	- 可以完全使用可以买到的商用组件搭配而成，这些商用组件都是大规模生产的产品，能够获得较高的性价比

- 与MPP的区别（体系结构方面）
	- 节点是完整的计算机，计算机可以是同构或异构
	- 节点都有自己的内存，甚至有自己的完整的操作系统；而MPP系统结点一般没有磁盘，只由单操作系统内核
	- MPP使用制造厂商专有的高速通信网络；COW一般采用公开销售的产品，是局域网或专线网，网络通常是与节点计算机的I/O总线相连（松散耦合），而MPP的网络接口是连到处理节点的存储总线上（紧耦合）

## 异构系统架构
- **多种**处理器或核心
- 使用**加速器**来提高性能或能源效率，通常结合专门的处理能力来处理特定任务
- 适合执行 SIMD 和 SIMT(T:threads)

——CPU——GPU——FPGA——AISC——
越左边越灵活（通用型）
越右边越高效（专用型）
### NVIDIA GPU
不关心控制、Cache，面积几乎都给了计算核心